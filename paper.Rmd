---
title: 'Claret: Using Data Types for Highly Concurrent Distributed Transactions'
sigplanconf: '10pt,preprint,nocopyrightspace'

author:
  - name: Brandon Holt
  - name: John Smith
  - name: Arthur Dent

emails: '{bholt,jsmith,adent}\@cs.uw.edu'

organization:
  - name: University of Washington

conference:
  name: PaPoC 2015
  location: 'April 21, 2015, Bordeaux, France'
  year: 2015
  
doi: 0

layout: sigplanconf
bibliography: biblio.bib

abstract: |
  Building database applications out of data structures rather than simple string values allows the flexibility and fine-grained control of typical key-value databases while providing better performance and scalability. Composing transactions out of linearizable data structure operations exposes concurrency in a safe way, making it simple to implement efficiently and easy to reason about.
---
```{r setup, include=FALSE}
opts_chunk$set(dev='pdf', echo=F, message=F, warning=F, error=F, fig.width=3.6, fig.height=3, include=F)
source('project.R')
```

## Introduction
Most web-scale services these days rely on NoSQL databases to provide scalable, fault-tolerant persistent storage.

A recent trend in the transactional memory community is to raise the level of abstraction to data structure operations to reduce the overhead of tracking individual memory accesses as well as leverage the commutativity of operations to avoid unnecessary rollbacks. [@Herlihy:PPoPP08]

In [#eval] we consider a case study modeled after Twitter.

## Commutativity

Though *commutativity* is often discussed in terms of an operation commuting with all other operations, it is actually more nuanced. If a pair of operations commute, then executing them in either order will produce the same result. Using the definitions from \cite{Kulkarni:PLDI11}, whether or not a pair of method invocations commute is a property of the data type and is a function of the methods, their arguments, their return values, and the *abstract* state of their target. We call the full set of commutativity rules for a data type its *commutativity specification.* An example specification for a *set* is shown in [#spec].

\begin{table}
\centering
\begin{tabular}{lll}
\textbf{method:} & \textbf{commutes with:} & \textbf{when:} \\
\hline
\texttt{add(x) -> void} & \texttt{add(y)} & $\forall x, y$ \\
\texttt{remove(x) -> void} & \texttt{remove(y)} & $\forall x, y$ \\
    & \texttt{add(y)} & $x \ne y$ \\
\texttt{size() -> int} & \texttt{add(x)} & $x \in Set$ \\
    & \texttt{remove(x)} & $x \notin Set$ \\
\texttt{getall() -> list} & \texttt{add(x)} & $x \in Set$ \\
    & \texttt{remove(x)} & $x \notin Set$ \\
    & \texttt{size()} & $always$ \\
    \hline
\end{tabular}
\caption{\label{spec} Commutativity Specification for Set.}
\end{table}

## Evaluation {#eval}
To show the efficacy of leveraging commutative operations, we use an application typical of web workloads: a simplified Twitter clone known as *Retwis*. In [#tput] you can see that with commutativity, transaction throughput scales with increased concurrency.

#### Figure: {#tput}
```{r throughput}

d <- data(db("
    select * from tapir where 
    generator_time is not null and total_time is not null
    and name like 'claret-v0.14%'
  ",
    factors=c('nshards', 'nclients'),
    numeric=c('total_time', 'txn_count')
))
d.u <- subset(d, nshards == 4 & initusers == 4096 
                & grepl('geom_repost|read_heavy', mix))
ggplot(d.u, aes(x=nclients, y=throughput/1000, 
        group=cc, fill=cc, color=cc, linetype=cc))+
    stat_summary(fun.y=mean, geom="line", size=0.4)+
    xlab('Concurrent clients')+ylab('Throughput (k trans. / sec)')+
    expand_limits(y=0)+
   facet_wrap(~workload)+
    theme_mine+
    theme(legend.position='right', legend.direction='vertical', legend.title.align=0)+
    cc_scales(title='Concurrency\ncontrol:')
```
![](figure/throughput-1.pdf)
Caption: Throughput, varying the number of concurrent clients.

This is no longer in the caption.
